{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969afb63-9039-4383-94b0-1adb32321d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM과 RAG 기술을 활용해 사용자 질문에 답변하는 챗봇\n",
    "# PDF 파일을 불러와서 챗봇을 구축하며 이번주 배운 내용을 실습하여 복습\n",
    "# 프론트 없이 백에서만 구동되는것을 확인 가능하면 OK⇒ jupyter notebook에서 확인하는 식\n",
    "\n",
    "\n",
    "# openai_api_key = \n",
    "#추후 공부를 위해 참고자료 : Gemini API 발급방법\n",
    "#import os\n",
    "#api_key = 'Gemini api key'\n",
    "#os.environ[\"GOOGLE_API_KEY\"] = api_key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b84c09-2f5b-473f-9cd8-4caac14426b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in c:\\users\\workp\\anaconda3\\lib\\site-packages (0.2.8)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langchain_openai) (0.3.18)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.54.0 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langchain_openai) (1.54.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langchain_openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (4.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\workp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\workp\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\workp\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain_openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain_openai) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.17->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.17->langchain_openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\workp\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.54.0->langchain_openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055c9acb-285b-4657-b4a2-0084150ce525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n"
     ]
    }
   ],
   "source": [
    "# 사용 환경을 준비\n",
    "import os\n",
    "from getpass import getpass\n",
    "import openai\n",
    "\n",
    "#getpass란? 사용자로부터 비밀번호를 입력받고, 그 입력이 화면에 출력되지 않도록 한다.\n",
    "# getpass로 OpenAI API 키 입력 받기\n",
    "api_key = getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# 환경 변수에 API 키 설정\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "# OpenAI API 키를 환경 변수에서 가져오기\n",
    "# .getenv()는 파이썬의 os 모듈에 포함된 함수로, 환경 변수(environment variable)의 값을 가져오는 데 사용한다.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7ebd96-5d86-4d49-b9ad-8cc67e274762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#검색 기반 생성(RAG)\n",
    "#LangChain을 사용하여 질문에 답할 때 관련 문서를 검색하고, \n",
    "#해당 내용을 바탕으로 응답을 생성할 수 있다. 이를 통해 최신 정보에 기반한 답변을 생성할 수 있기에 LangChian으로 사용\n",
    "\n",
    "#OpenAI의 GPT-4o-mini 모델을 LangChain을 통해 사용해 보자. ChatOpenAI를 이용해 초기화한다.\n",
    "\n",
    "\n",
    "# openai 모델 로드하기\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "#추후 공부를 위해 참고자료 : Gemini API 모델 로드 및 모델 초기\n",
    "#from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "#model = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "# 모델 초기화, 최신 모델로\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2acb7d9c-7c5b-4ae8-8120-5a988f7f8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추후 공부를 위해\n",
    "# 인공지능최신산업동향\n",
    "    # LLM에 업데이트 되어있지 '않은' 최신 인공지능산업동향에 대해 정확히 답변할 수 있는 챗봇\n",
    "    # 'RAG의 필요성'을 잘 드러내는 자료\n",
    "# 초거대 언어모델 연구 동향\n",
    "    # LLM에 업데이트 되어있지 '않은' 최신 인공지능 연구동향에 대해 정확히 답변할 수 있는 챗봇\n",
    "    # 'LLM 요소에 익숙'해지기 좋은 자료\n",
    "# 2024 세금 절약 가이드\n",
    "    # LLM에 업데이트 되어있지 '않은' 한국의 세금 절약 방법에 대해 정확히 답변할 수 있음\n",
    "    # 'RAG 의 필요성'을 드러내며, RAG 솔루션회사가 주로 법률, 세금 등 의 도메인에서 많이 필요로 하기에 의미있는 자료\n",
    "\n",
    "\n",
    "# 첫번째 문서 로드하기\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "#import os\n",
    "#file_path = os.path.join(\"C:\", \"Users\", \"workp\", \"OneDrive\", \"LLM&RAG\", \"인공지능 산업의 최신 동향.pdf\")\n",
    "#loader = PyPDFLoader(file_path)\n",
    "\n",
    "file_path = \"인공지능최신동향.pdf\"\n",
    "loader = PyPDFLoader(\"C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf\")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a520347-a326-4695-8c50-5113af7eac20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 0}, page_content='2024년 11월호'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='2024년 11월호'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='Ⅰ. 인공지능 산업 동향 브리프 1. 정책/법제    ▹ 미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석························1'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='▹ 미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표·····························2   ▹ 유로폴, 법 집행에서 AI의 이점과'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='AI의 이점과 과제를 다룬 보고서 발간··············································3   ▹ OECD, 공공 부문의 AI 도입을 위한 G7'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='도입을 위한 G7 툴킷 발표··························································4   ▹ 세계경제포럼, 생성AI 시대의'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='생성AI 시대의 거버넌스 프레임워크 제시····················································5  2. 기업/산업    ▹ CB인사이츠'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='▹ CB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중··············6   ▹ 메타, 동영상 생성AI 도구 ‘메타 무비 젠’'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='‘메타 무비 젠’ 공개···································································7   ▹ 메타, 이미지와 텍스트'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개···························8   ▹ 앨런AI연구소, 벤치마크 평가에서 GPT-4o'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개····9   ▹ 미스트랄AI, 온디바이스용 AI 모델 ‘레 미니스트로’'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='‘레 미니스트로’ 공개·················································10   ▹ 카카오, 통합 AI 브랜드 겸 신규 AI 서비스'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='신규 AI 서비스 ‘카나나’ 공개···············································11 3. 기술/연구   ▹ 2024년 노벨 물리학상과'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='노벨 물리학상과 화학상, AI 관련 연구자들이 수상············································12   ▹ 미국 국무부, AI 연구에서'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표························13   ▹ 일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='평가 관점 가이드 발간········································14   ▹ 구글 딥마인드, 반도체 칩 레이아웃 설계하는 AI 모델 ‘알파칩’'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='모델 ‘알파칩’ 발표·····························15   ▹ AI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='대안 필요성 강조····························16    4. 인력/교육        ▹ MIT 산업성과센터, 근로자 관점에서 자동화 기술의 영향'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='기술의 영향 조사········································17   ▹ 다이스 조사, AI 전문가의 73%는 2025년 중 이직'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='중 이직 고려················································18   ▹ 가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='역량 향상 필요 ·····························19   ▹ 인디드 조사 결과, 생성AI가 인간 근로자 대체할 가능성은'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='대체할 가능성은 희박·····································20'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='Ⅱ. 주요 행사  ▹NeurIPS 2024'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='···································································································'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='·····························21'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='▹GenAI Summit Maroc 2024'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='·····························································································21'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='▹AI Summit Seoul 2024'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='···································································································'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 1}, page_content='············21'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 2}, page_content='Ⅰ. 인공지능 산업 동향 브리프'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n1'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석n미국 민권위원회에 따르면 연방정부와 법 집행기관에서 얼굴인식 기술이 빠르게 도입되고 있으나 이를 관리할'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='이를 관리할 지침과 감독의 부재로 민권 문제를 초래할 위험 존재n미국 민권위원회는 연방정부의 책임 있는 얼굴인식 기술 사용을 위해 운영 프로토콜 개발과 실제 사용 상황의 얼굴인식'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='상황의 얼굴인식 기술 평가 및 불평등 완화, 지역사회의 의견 수렴 등을 권고'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='KEY Contents'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='£연방정부의 얼굴인식 기술 도입에 대한 지침과 감독 부재로 민권 문제를 초래할 위험 존재n미국 민권위원회(U.S. Commission on Civil Rights)가 2024년'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='2024년 9월 19일 연방정부의 얼굴인식 기술 사용이 민권에 미치는 영향을 분석한 보고서를 발간∙AI 기술의 일종인 얼굴인식 기술은 연방정부와 법 집행기관에서 빠르게 도입되고'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='빠르게 도입되고 있으며, 일례로 법무부 연방수사국(FBI)은 범죄 수사 및 용의자 수색용 단서 확보를 위해 얼굴인식 기술을 가장 빈번히 사용∙그러나 얼굴인식 기술의 책임 있는'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='기술의 책임 있는 사용을 위한 연방 지침과 감독은 실제 활용 사례보다 뒤처졌으며, 현재 연방정부의 얼굴인식 기술이나 여타 AI 기술 사용을 명시적으로 규제하는 법률도 부재'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='법률도 부재  n보고서에 따르면 얼굴인식 기술의 무분별한 사용은 편향, 개인정보 침해, 적법 절차의 미준수 및 차별적 영향과 같은 민권 문제를 초래할 위험 보유∙얼굴인식 기술의'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='기술의 정확도는 인종, 성별, 연령 등 인구통계학적 요인에 따라 달라질 수 있으며, 이는 식별 오류 및 부정확한 체포로 이어져 유색인종을 비롯한 특정 집단에 차별적 결과를 초래할'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='결과를 초래할 위험 존재∙정부 기관이 사전 영장이나 정당한 이유 없이 얼굴인식 기술을 광범위하게 사용할 경우 개인을 지속적으로 추적하고 감시함으로써 개인정보 보호 권리에 심각한'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='권리에 심각한 영향을 미칠 위험 존재∙법 집행기관의 얼굴인식 기술 사용 시 부정확한 식별 및 편향으로 인해 개인이 법의 보호를 받아 공정하고 올바르게 대우받을 권리를 침해할'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='권리를 침해할 가능성도 존재£민권위원회, 연방정부의 책임 있는 얼굴인식 기술 사용을 위한 권고사항 제시n민권위원회는 연방정부의 얼굴인식 기술 사용과 관련해 다음과 같은 권고사항을'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='같은 권고사항을 제시∙국립표준기술연구소(NIST)는 정부 기관의 얼굴인식 기술 시스템 도입 시의 효과와 공평성, 정확성 평가에 사용할 수 있는 운영 테스트 프로토콜의 개발'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='프로토콜의 개발 필요∙각 연방정부 기관의 최고AI책임자는 실제 사용 상황에서 얼굴인식 기술을 평가하고 차별이나 편견으로 인한 불평등을 완화하며, 얼굴인식 기술의 사용으로 영향을'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='사용으로 영향을 받는 지역사회의 의견을 수렴 필요∙얼굴인식 기술 제공업체는 다양한 인구통계 집단에 대한 높은 정확도를 보장하기 위해 지속적인 교육과 지원, 업데이트를 제공 필요'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='제공 필요 ☞ 출처: U.S. Commission on Civil Rights, The Civil Rights Implications of the Federal Use of'),\n",
       " Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='Use of Facial Recognition Technology, 2024.09.19.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 청크로 나누기\n",
    "# 청킹을 완수하면 청킹된 내용을 상위 50개까지 출력하고, 각 청킹방식과 parameter의 뜻을 markdown으로 정리\n",
    "# i 또는 ii 사용해서 나타내기\n",
    "\n",
    "\n",
    "# i. CharacterTextSplitter \n",
    "    #from langchain.text_splitter import CharacterTextSplitter\n",
    "    #text_splitter = CharacterTextSplitter(\n",
    "        #separator=\"\\n\\n\",\n",
    "        #chunk_size=100,\n",
    "        #chunk_overlap=10,\n",
    "        #length_function=len,\n",
    "        #is_separator_regex=False,\n",
    "    #)\n",
    "    #splits = text_splitter.split_documents(docs)\n",
    "\n",
    "#ii. RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "splits = recursive_text_splitter.split_documents(docs)\n",
    "splits[0:50] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6af7b7-96aa-426c-a585-f3b7706bb18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 임베딩 생성\n",
    "# OpenAI 모델의 경우 OpenAIEmbeddings , Gemini 모델의 경우 GoogleGenerativeAIEmbeddings를 이용해 텍스트를 벡터로 변환할 벡터 임베딩을 생성\n",
    "\n",
    "#추후 공부를 위한 : Gemini\n",
    "#GoogleGenerativeAIEmbeddings로 벡터 임베딩 생성\n",
    "#from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "#Gemini 임베딩 모델 초기\n",
    "#embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # gemini의 임베딩 모델\n",
    "\n",
    "# OpenAI의 OpenAIEmbeddings을 이용해서 텍스트를 벡터로 변환할 벡터 임베딩 생성\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f552396e-0aa7-438f-99ae-8cdc20a22192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\workp\\anaconda3\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\workp\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\workp\\anaconda3\\lib\\site-packages (from faiss-cpu) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a95640b-49c5-4f8e-b235-0a6994d98480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#로컬 저장소도 따로 해야하나요?\n",
    "\n",
    "# 벡터 스토어 생성\n",
    "# 앞서 만든 벡터 임베딩과 청크된 문서를 활용하여 FAISS 벡터 스토어를 생성\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "vector_store = FAISS.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c41106ef-2d44-41a9-8d1b-482ff73ad8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 체인에서 사용할 수 있도록 FAISS를 retriever로 변환\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "683e0ad1-e750-4b2b-a665-728cb0daa802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain의 모델과 프롬프트를 연결하여 RAG 체인을 구성\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the question using only the following context.\"),\n",
    "    (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {question}\")\n",
    "])\n",
    "\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "# 문서 리스트를 텍스트로 변환하는 단계 추가\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):  # config 인수 추가\n",
    "        # context의 각 문서를 문자열로 결합\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        return {\"context\": context_text, \"question\": inputs[\"question\"]}\n",
    "\n",
    "# RAG 체인에서 각 단계마다 DebugPassThrough 추가\n",
    "rag_chain_debug = {\n",
    "    \"context\": retriever,                    # 컨텍스트를 가져오는 retriever\n",
    "    \"question\": DebugPassThrough()        # 사용자 질문이 그대로 전달되는지 확인하는 passthrough\n",
    "}  | DebugPassThrough() | ContextToText()|   contextual_prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e4f8b-4fdd-4e43-ad86-c94bea3f48ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  2024년 9월 19일날 정보를 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug Output: 2024년 9월 19일날 정보를 알려줘\n",
      "Debug Output: {'context': [Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 0}, page_content='2024년 11월호')], 'question': '2024년 9월 19일날 정보를 알려줘'}\n",
      "Final Response:\n",
      "죄송하지만, 2024년 9월 19일에 대한 구체적인 정보는 제공할 수 없습니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  인공지능이란?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug Output: 인공지능이란?\n",
      "Debug Output: {'context': [Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 23}, page_content='-신경정보처리시스템재단은 인공지능과 머신러닝 분야의 연구 성과 교환을 촉진하는 것을 목적으로 하는 비영리 법인으로 매년 학제간 학술대회(NeurIPS)를 주최-이번 제38회')], 'question': '인공지능이란?'}\n",
      "Final Response:\n",
      "인공지능은 컴퓨터 시스템이 인간과 유사한 방식으로 학습, 추론, 문제 해결, 이해 및 언어 처리 등의 지능적인 작업을 수행할 수 있도록 하는 기술 및 이론을 의미합니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  인공지능을 영어로 어떻게 표현하나요?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug Output: 인공지능을 영어로 어떻게 표현하나요?\n",
      "Debug Output: {'context': [Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 22}, page_content='대체할 가능성이 제한적∙일례로 생성AI는 디지털 기술 비중이 큰 소프트웨어 개발 직종의 구인 공고에서 통상 제시되는 직무 기술의 71%에 대하여 인간을 대체할 가능성이 “보통”')], 'question': '인공지능을 영어로 어떻게 표현하나요?'}\n",
      "Final Response:\n",
      "인공지능은 영어로 \"artificial intelligence\"라고 표현합니다.\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "# 챗봇 구동 확인\n",
    "# 질문에 응답하는 챗봇을 구동하여 질문해보기\n",
    "# 같은 질문을 일반 chat gpt 혹은 Gemini에 질문해보고 답변을 비교해보고, 왜 RAG이 필요한지 간단히 markdown으로 서술\n",
    "\n",
    "# 무한 루프(동작 확인)\n",
    "while True: \n",
    "    print(\"========================\")\n",
    "    query = input(\"질문을 입력하세요 (종료하려면 'exit' 입력): \")\n",
    "    \n",
    "    # 사용자가 'exit'을 입력하면 루프 종료\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"프로그램을 종료합니다.\")\n",
    "        break  # 루프 종료\n",
    "        \n",
    "    # query를 전달하여 응답 받기\n",
    "    response = rag_chain_debug.invoke(query) \n",
    "    print(\"Final Response:\")\n",
    "    print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffca948-5530-4ea2-bde8-3cfa861e3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#일단 공부 후 이 방식에서 수정해서 완성하기\n",
    "#시간되면 도전과제도 해보기\n",
    "#제출은 19일까지\n",
    "#평가 기준 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37598772-2c86-4121-8b78-b44deb629f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2024년 9월 19일 정보 물어본 이유 :  Document(metadata={'source': 'C:/Users/workp/OneDrive/LLM&RAG/인공지능 산업의 최신 동향.pdf', 'page': 3}, page_content='2024년 9월 19일 연방정부의 얼굴인식 기술 사용이 민권에 미치는 영향을 분석한 보고서를 발간∙AI 기술의 일종인 얼굴인식 기술은 연방정부와 법 집행기관에서 빠르게 도입되고'),\n",
    "# 인공지능이란?: 인공지능은 컴퓨터 시스템이 인간과 유사한 방식으로 학습, 추론, 문제 해결, 이해 및 언어 처리 등의 지능적인 작업을 수행할 수 있도록 하는 기술 및 이론을 의미합니다.\n",
    "# 인공지능을 영어로 어떻게 표현하나요?: 인공지능은 영어로 \"artificial intelligence\"라고 표현합니다.\n",
    "\n",
    "#왜 RAG이 필요한지 간단히 markdown으로 서술\n",
    "#RAG 모델은 자체 데이터를 기반으로 지식 저장소를 만들고, 이로부터 AI가 상황에 맞는 답변을 적시에 제공할 수 있도록 지원하기에, 동적으로 활도함으로써 보다 유연한 답변을 할 수 있기에 RAG 모델이 필요하다고 생각합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb773708-cfc4-4307-a28e-f9a79fa90848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
